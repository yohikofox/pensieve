# language: fr

Fonctionnalit√©: Story 4.2 - Digestion IA - R√©sum√© et Id√©es Cl√©s

  En tant qu'utilisateur
  Je veux que mes captures soient automatiquement analys√©es par l'IA pour g√©n√©rer un r√©sum√© concis et extraire les id√©es cl√©s
  Afin que je puisse rapidement comprendre l'essence de mes pens√©es sans tout relire

  Contexte:
    √âtant donn√© le backend est d√©marr√©
    Et RabbitMQ est accessible
    Et OpenAI API est accessible

  # ============================================================================
  # AC1: GPT-4o-mini Integration and Prompt Engineering
  # ============================================================================

  @AC1 @gpt-integration
  Sc√©nario: Digestion d'un contenu court avec GPT-4o-mini
    √âtant donn√© qu'un job de digestion est re√ßu avec un contenu de 100 mots
    Quand le service OpenAI traite le contenu
    Alors GPT-4o-mini est utilis√© comme mod√®le (gpt-4o-mini)
    Et le timeout est configur√© √† 30 secondes
    Et la temp√©rature est configur√©e √† 0.7
    Et max_tokens est configur√© √† 500
    Et le r√©sultat contient un summary de 2-3 phrases
    Et le r√©sultat contient entre 3 et 10 ideas
    Et le r√©sultat contient un niveau de confidence (high/medium/low)

  @AC1 @prompt-engineering
  Sc√©nario: Validation du format JSON structur√© avec Zod
    √âtant donn√© qu'un job de digestion est re√ßu
    Quand le service OpenAI traite le contenu
    Alors la r√©ponse GPT respecte le format JSON structur√©
    Et le schema Zod valide le champ "summary" (10-500 caract√®res)
    Et le schema Zod valide le champ "ideas" (tableau de 1-10 √©l√©ments)
    Et le schema Zod valide chaque idea (5-200 caract√®res)
    Et le schema Zod valide le champ "confidence" (enum: high/medium/low)

  @AC1 @prompt-engineering @fallback
  Sc√©nario: Fallback sur prompt plain-text si JSON √©choue
    √âtant donn√© qu'un job de digestion est re√ßu
    Et que le prompt principal JSON √©choue
    Quand le service OpenAI utilise le fallback
    Alors un prompt plain-text est utilis√©
    Et le niveau de confidence est downgraded √† "medium"
    Et la r√©ponse est pars√©e manuellement
    Et le r√©sultat contient un summary valide
    Et le r√©sultat contient des ideas valides

  # ============================================================================
  # AC2: Text Capture Digestion Flow
  # ============================================================================

  @AC2 @text-capture
  Sc√©nario: Digestion d'une capture texte simple
    √âtant donn√© qu'une capture texte "R√©union √©quipe: discut√© roadmap Q1, priorit√© feature X, deadline mars" existe
    Quand un job de digestion est trait√©
    Alors le ContentExtractorService extrait le contenu texte brut
    Et le contentType est "text"
    Et le contenu est envoy√© √† GPT-4o-mini
    Et un Thought est cr√©√© avec le summary
    Et 3 Ideas sont cr√©√©es
    Et le statut de la Capture est mis √† jour √† "digested"
    Et le temps de traitement est < 30 secondes

  @AC2 @text-capture @long
  Sc√©nario: Digestion d'une capture texte longue avec chunking
    √âtant donn√© qu'une capture texte de 10,000 mots existe
    Quand un job de digestion est trait√©
    Alors le ContentChunkerService d√©tecte que le contenu d√©passe 4000 tokens
    Et le contenu est divis√© en chunks de 4000 tokens avec overlap de 200 tokens
    Et chaque chunk est trait√© s√©quentiellement par GPT-4o-mini
    Et les summaries sont fusionn√©s en un summary coh√©rent
    Et les ideas sont d√©dupliqu√©es (seuil de similarit√© 0.8)
    Et wasChunked est true dans le r√©sultat
    Et chunkCount est > 1

  # ============================================================================
  # AC3: Audio Capture Digestion Flow
  # ============================================================================

  @AC3 @audio-capture
  Sc√©nario: Digestion d'une capture audio transcrite
    √âtant donn√© qu'une capture audio a √©t√© transcrite par Whisper
    Et que la transcription contient "Id√©e pour nouvelle feature: syst√®me de tags pour organiser les captures"
    Quand un job de digestion est trait√©
    Alors le ContentExtractorService extrait la transcription
    Et le contentType est "audio"
    Et le prompt GPT adapte son style pour du contenu audio transcrit
    Et un Thought est cr√©√© avec le summary
    Et au moins 1 Idea est extraite
    Et le statut de la Capture est mis √† jour √† "digested"

  @AC3 @audio-capture @empty
  Sc√©nario: Gestion du contenu audio vide ou invalide
    √âtant donn√© qu'une capture audio a une transcription vide
    Quand un job de digestion est trait√©
    Alors le ContentExtractorService l√®ve une exception "Empty content"
    Et le job √©choue
    Et le statut de la Capture est mis √† jour √† "digestion_failed"
    Et l'erreur est logu√©e avec le message "Empty content: {captureId}"

  # ============================================================================
  # AC4: Thought and Ideas Persistence
  # ============================================================================

  @AC4 @persistence
  Sc√©nario: Cr√©ation atomique d'un Thought avec ses Ideas
    √âtant donn√© qu'un job de digestion retourne un summary et 5 ideas
    Quand ThoughtRepository.createWithIdeas est appel√©
    Alors un Thought est cr√©√© avec le summary
    Et 5 Ideas sont cr√©√©es avec orderIndex (0-4)
    Et toutes les entit√©s partagent le m√™me userId et captureId
    Et la transaction est atomique (tout ou rien)
    Et un confidenceScore num√©rique est calcul√© (high=0.9, medium=0.6, low=0.3)
    Et processingTimeMs est enregistr√©

  @AC4 @persistence @rollback
  Sc√©nario: Rollback en cas d'√©chec de cr√©ation des Ideas
    √âtant donn√© qu'un job de digestion retourne un summary et 3 ideas
    Et que la cr√©ation de la 2√®me Idea √©choue
    Quand ThoughtRepository.createWithIdeas est appel√©
    Alors la transaction est rollback
    Et aucun Thought n'est cr√©√©
    Et aucune Idea n'est cr√©√©e
    Et une exception est lev√©e

  @AC4 @persistence @event
  Sc√©nario: Publication de l'√©v√©nement DigestionCompleted
    √âtant donn√© qu'un job de digestion se termine avec succ√®s
    Quand le Thought et les Ideas sont cr√©√©s
    Alors un √©v√©nement "digestion.completed" est publi√©
    Et l'√©v√©nement contient thoughtId
    Et l'√©v√©nement contient captureId
    Et l'√©v√©nement contient userId
    Et l'√©v√©nement contient summary
    Et l'√©v√©nement contient ideasCount
    Et l'√©v√©nement contient processingTimeMs
    Et l'√©v√©nement contient completedAt timestamp

  # ============================================================================
  # AC5: Real-Time Feed Update Notification
  # ============================================================================

  @AC5 @notification @skip-not-implemented
  Sc√©nario: Notification temps-r√©el apr√®s digestion compl√©t√©e
    √âtant donn√© qu'un √©v√©nement "digestion.completed" est publi√©
    Quand l'√©v√©nement est re√ßu par le handler
    Alors une notification temps-r√©el est envoy√©e au client
    Et le Feed mobile est mis √† jour automatiquement
    Et l'animation de germination est d√©clench√©e

  # ============================================================================
  # AC6: Long Content Chunking Strategy
  # ============================================================================

  @AC6 @chunking
  Sc√©nario: D√©tection automatique du besoin de chunking
    √âtant donn√© qu'un contenu de 15,000 tokens est re√ßu
    Quand ContentChunkerService.processContent est appel√©
    Alors le service d√©tecte que le contenu d√©passe maxTokensPerChunk (4000)
    Et le chunking est activ√© automatiquement
    Et le r√©sultat contient wasChunked=true

  @AC6 @chunking @overlap
  Sc√©nario: Chunking avec overlap pour pr√©server le contexte
    √âtant donn√© qu'un contenu de 12,000 tokens est re√ßu
    Quand le contenu est divis√© en chunks
    Alors chaque chunk contient max 4000 tokens
    Et chaque chunk (sauf le premier) commence avec 200 tokens du chunk pr√©c√©dent
    Et le nombre de chunks est calcul√©: ceil(12000 / 4000) = 3 chunks

  @AC6 @chunking @deduplication
  Sc√©nario: D√©duplication des ideas entre les chunks
    √âtant donn√© que chunk 1 retourne ["Feature A", "Feature B"]
    Et que chunk 2 retourne ["Feature B", "Feature C"]
    Quand les ideas sont fusionn√©es
    Alors la similarit√© Jaccard est calcul√©e pour chaque paire
    Et "Feature B" (identique) est d√©dupliqu√©e
    Et le r√©sultat final contient ["Feature A", "Feature B", "Feature C"]

  @AC6 @chunking @confidence
  Sc√©nario: Downgrade de confidence pour contenu tr√®s long
    √âtant donn√© qu'un contenu est divis√© en 5 chunks
    Et que chaque chunk retourne confidence="high"
    Quand les r√©sultats sont fusionn√©s
    Alors la confidence finale est downgraded √† "medium"
    Et chunkCount (5) est sup√©rieur √† 3

  # ============================================================================
  # AC7: Error Handling and Retry Logic
  # ============================================================================

  @AC7 @error-handling
  Sc√©nario: Retry automatique apr√®s √©chec temporaire (timeout)
    √âtant donn√© qu'un job de digestion timeout apr√®s 30s
    Quand le job √©choue
    Alors RabbitMQ requeue le job avec retry delay (5s ‚Üí 15s ‚Üí 45s)
    Et retryCount est incr√©ment√©
    Et le job est retrait√© automatiquement

  @AC7 @error-handling @max-retries
  Sc√©nario: √âchec permanent apr√®s 3 tentatives
    √âtant donn√© qu'un job √©choue 3 fois cons√©cutives
    Quand la 3√®me tentative √©choue
    Alors le statut de la Capture est mis √† jour √† "digestion_failed"
    Et un √©v√©nement "digestion.job.failed" est publi√©
    Et le job est d√©plac√© vers la dead-letter queue
    Et l'erreur est logu√©e avec stack trace

  @AC7 @error-handling @api-errors
  Sc√©nario: Gestion des erreurs API OpenAI
    √âtant donn√© qu'OpenAI retourne une erreur 429 (rate limit)
    Quand le job est trait√©
    Alors l'erreur est captur√©e et logu√©e
    Et le job est retent√© avec exponential backoff
    Et le statut de la Capture reste "digesting" pendant le retry

  # ============================================================================
  # AC8: Low Confidence and Edge Cases
  # ============================================================================

  @AC8 @low-confidence
  Sc√©nario: D√©tection de faible confidence sur contenu court
    √âtant donn√© qu'un contenu de 3 mots "Acheter du lait" est re√ßu
    Quand GPT traite le contenu
    Alors le niveau de confidence retourn√© est "low"
    Et le confidenceScore est 0.3
    Et le Thought est cr√©√© avec cette confidence
    Et un flag UI indique la faible fiabilit√©

  @AC8 @low-confidence @ui-flag
  Sc√©nario: Flag UI pour faible confidence
    √âtant donn√© qu'un Thought a √©t√© cr√©√© avec confidence="low"
    Quand le Thought est affich√© dans le Feed
    Alors un indicateur visuel signale la faible confidence
    Et l'utilisateur peut consulter le contenu original

  @AC8 @edge-cases @special-chars
  Sc√©nario: Gestion des caract√®res sp√©ciaux et √©mojis
    √âtant donn√© qu'un contenu contient "üöÄ Lancer projet 2026 üí° Id√©e g√©niale"
    Quand le job est trait√©
    Alors les √©mojis sont pr√©serv√©s dans le summary
    Et les caract√®res sp√©ciaux ne causent pas d'erreur de parsing
    Et le r√©sultat est valide

  @AC8 @edge-cases @code
  Sc√©nario: Gestion du code source dans le contenu
    √âtant donn√© qu'un contenu contient du code TypeScript
    """
    function hello() {
      console.log("Hello World");
    }
    """
    Quand le job est trait√©
    Alors le code est trait√© comme du texte brut
    Et le summary d√©crit l'intention du code
    Et les ideas extraient les concepts cl√©s
